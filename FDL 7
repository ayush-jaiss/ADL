import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Set default figure size and use an available Matplotlib style
plt.rcParams['figure.figsize'] = (20, 15)
plt.style.use('ggplot')  

# Import required Keras modules
from tensorflow.keras import layers
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Model


def preprocess(array):
    array = array.astype("float32") / 255.0
    array = np.reshape(array, (len(array), 28, 28, 1))  # Change to 28x28
    return array

def noise(array):
    noise_factor = 0.4
    noisy_array = array + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=array.shape)
    return np.clip(noisy_array, 0.0, 1.0)

def display(array1, array2):
    n = 10
    indices = np.random.randint(len(array1), size=n)
    images1 = array1[indices, :]
    images2 = array2[indices, :]

    plt.figure(figsize=(20, 4))
    for i, (image1, image2) in enumerate(zip(images1, images2)):
        # Display the first set of images
        ax = plt.subplot(2, n, i + 1)
        plt.imshow(image1.reshape(28, 28))
        plt.gray()
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
        
        # Display the second set of images
        ax = plt.subplot(2, n, i + 1 + n)
        plt.imshow(image2.reshape(28, 28))
        plt.gray()
        ax.get_xaxis().set_visible(False) 
        ax.get_yaxis().set_visible(False)

    plt.show()


(train_data, _), (test_data, _) = mnist.load_data()

# Normalize and reshape the data
train_data = preprocess(train_data)
test_data = preprocess(test_data)

# Create a copy of the data with added noise
noisy_train_data = noise(train_data)
noisy_test_data = noise(test_data)

# Display the train data and a version of it with added noise
display(train_data, noisy_train_data)


encoder_input = layers. Input (shape=(28, 28, 1))
# Encoder
x = layers.Conv2D(32,(3,3),activation="relu", padding="same")(encoder_input)
x = layers.MaxPooling2D((2, 2), padding="same") (x)
x = layers.Conv2D(32, (3, 3), activation="relu", padding="same") (x)
x = layers.MaxPooling2D((2, 2), padding="same") (x)

encoder = Model(encoder_input, x, name='encoder')
encoder.summary()

# Decoder
x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation="relu", padding="same") (x)
x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation="relu", padding="same") (x)
x = layers.Conv2D(1, (3, 3), activation="sigmoid", padding="same") (x)

# Autoencoder
autoencoder = Model(encoder_input, x, name='autoencoder')
autoencoder.compile(optimizer="adam", loss="binary_crossentropy")
autoencoder.summary()


autoencoder.fit(
    x=train_data,
    y=train_data,
    epochs=10,
    batch_size=128,
    shuffle=True,
    validation_data=(test_data, test_data)
)


predictions = autoencoder.predict(test_data)
display(test_data, predictions)


test_data[0].reshape(-1,28,28,1).shape


encoded = encoder.predict(test_data[0].reshape(-1,28,28,1))
encoded.shape


plt.imshow(encoder.predict(test_data[0].reshape(-1,28,28,1)).reshape(7,7,-1)[:,:,1])


for i in range(32):
    ax = plt.subplot(5, 8, i+1)
    plt.imshow(encoded.reshape(7,7,-1)[:,:,i])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)


output = autoencoder.predict(test_data[0].reshape(-1,28,28,1)) 
plt.imshow(output.reshape(28,28))


autoencoder.fit(
    x=noisy_train_data,
    y=train_data,
    epochs=10,
    batch_size=128,
    shuffle=True,
    validation_data=(noisy_test_data, test_data)
)


predictions = autoencoder.predict(noisy_test_data)
display(noisy_test_data,predictions)


