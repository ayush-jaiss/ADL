In [5]: from keras.layers import Input, Dense 
from keras.models import Model
from keras.datasets import mnist 
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

In [7]: (XTrain, YTrain), (XTest, YTest) = mnist.load_data() 
print('XTrain class = ',type(XTrain))
print('YTrain class = ',type(YTrain))
# shape of our dataset.
print('XTrain shape = ',XTrain. shape)
print('XTest shape = ',XTest.shape) 
print('YTrain shape = ',YTrain.shape) 
print('YTest shape = ',YTest.shape)
 Number of  distinct vaLues of our NNZS T target 
 print('YTrain values = ', np. unique (YTrain)) 
 print('YTest values = ', np. unique (YTest))
# Distribution of- c Lasses in our dataset.
unique, counts = np. unique (YTrain, return_counts=True)
print('YTrain distribution = ',dict (zip(unique, counts))) 
unique, counts = np. unique (YTest, return_counts=True) 
print('YTest distribution = ',dict(zip(unique, counts)))

 
ln[11]: XTrain = XTrain.astype('float32') / 255
XTest  = XTest. astype( 'I-1oat32' )  /  255
#data reshapp!ng.
XTrain = XTrain.reshape((len(XTrain), np. prod (XTrain.shape[1:]))) 
XTest=XTest.reshape((len(XTest), np.prod(XTest.shape[1:])))
print (XTrain.shape) 
print (XTest.shape)


ln[15]:InputModel = Input (shape=(784,))
EncodedLayer =Dense(32, activation='relu')(InputModel) 
DecodedLayer = Dense(784, activation='sigmoid') (EncodedLayer) 
AutoencoderModel = Model (InputModel, DecodedLayer)
# we can summarize our nodeL.
AutoencoderMode1.summary()

ln[19]:AutoencoderModel.compile(optimizer='adam', loss=' binary crossentropy') 
history = AutoencoderModel.fit(XTrain, XTrain,
batch size=25, epochs=10, shuffle=True,
validation_data: (XTest, XTest))
# make prediction to decode the digits 
DecodedDigits = AutoencoderModel.predict(XTest)

ln[21]:def plotmodelhistory(history): 
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss']) 
plt.title('Autoencoder Model loss') 
plt.ylabel('Loss') 
plt.xlabel('Epoch')
plt.legend (['Train', 'Test'], loc='upper left') 
plt.show()
# List all data in history 
print  ( history. history. keys ( ) )
#visualiation of loss minimiation during the training process 
plotmodelhistory (history)


n=5
plt.figure(figsize=(20, 4))
for i in range(n):
ax = plt.subplot(2, n, i + 1) 
#input image 
plt.imshow(XTest[i+10].reshape(28, 28))
plt.gray() ax.get_xaxis().set_visible(False) 
ax.get_yaxis().set_visible(False)
ax = plt.subplot(2, n, i + 1 + n)
plt.imshow(DecodedDigits[i+10].reshape(28, 28)) 
plt.gray()
ax.get_xaxis().set_visible(False)
ax.get_yaxis().set_visible(False)
plt.show()


